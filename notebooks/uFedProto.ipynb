{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# !pip install torch torchvision numpy matplotlib scikit-learn pandas\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Print PyTorch version and GPU availability\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                    download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                    download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1, 1),  # 28x28 -> 28x28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),         # 28x28 -> 14x14\n",
    "            nn.Conv2d(32, 64, 3, 1, 1), # 14x14 -> 14x14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),         # 14x14 -> 7x7\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Prototype layer\n",
    "        self.prototype_layer = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Get features from classifier\n",
    "        features = self.classifier(x)\n",
    "        \n",
    "        # Generate prototypes\n",
    "        prototypes = self.prototype_layer(features)\n",
    "        \n",
    "        # Get classification output\n",
    "        output = self.fc_out(features)\n",
    "        \n",
    "        return output, prototypes, features\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_iid_data(dataset, num_clients=6, num_shards=200):\n",
    "    \"\"\"\n",
    "    Create non-IID data distribution by dividing data into shards\n",
    "    and distributing them among clients.\n",
    "    \"\"\"\n",
    "    # Calculate number of items per shard\n",
    "    num_items = len(dataset) // num_shards\n",
    "    \n",
    "    # Create index list and shuffle\n",
    "    idx_shard = list(range(num_shards))\n",
    "    random.shuffle(idx_shard)\n",
    "    \n",
    "    # Sort data by label\n",
    "    label_indices = defaultdict(list)\n",
    "    for idx, label in enumerate(dataset.targets):\n",
    "        label_indices[label.item()].append(idx)\n",
    "    \n",
    "    # Distribute shards to clients\n",
    "    client_data = [[] for _ in range(num_clients)]\n",
    "    shards_per_client = num_shards // num_clients\n",
    "    \n",
    "    for client_idx in range(num_clients):\n",
    "        start_shard = client_idx * shards_per_client\n",
    "        end_shard = start_shard + shards_per_client\n",
    "        \n",
    "        for shard_idx in idx_shard[start_shard:end_shard]:\n",
    "            start_idx = shard_idx * num_items\n",
    "            end_idx = start_idx + num_items\n",
    "            client_data[client_idx].extend(range(start_idx, end_idx))\n",
    "    \n",
    "    return [torch.utils.data.Subset(dataset, indices) for indices in client_data]\n",
    "\n",
    "# Create non-IID data splits\n",
    "client_datasets = create_non_iid_data(trainset, num_clients=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedProtoClient:\n",
    "    def __init__(self, model, train_data, test_data, client_id, device, learning_rate=0.01):\n",
    "        self.model = model.to(device)\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.client_id = client_id\n",
    "        self.device = device\n",
    "        self.optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        self.model.train()\n",
    "        train_loader = torch.utils.data.DataLoader(self.train_data, batch_size=32, shuffle=True)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                output, prototypes, _ = self.model(data)\n",
    "                \n",
    "                # Compute losses\n",
    "                cls_loss = self.criterion(output, target)\n",
    "                proto_loss = self.compute_prototype_loss(prototypes, target)\n",
    "                total_loss = cls_loss + 0.1 * proto_loss\n",
    "                \n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                epoch_loss += total_loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                total += target.size(0)\n",
    "            \n",
    "            acc = 100. * correct / total\n",
    "            print(f'Client {self.client_id}, Epoch {epoch+1}: '\n",
    "                  f'Loss: {epoch_loss/len(train_loader):.4f}, '\n",
    "                  f'Accuracy: {acc:.2f}%')\n",
    "    \n",
    "    def compute_prototype_loss(self, prototypes, targets):\n",
    "        prototype_loss = 0\n",
    "        for c in range(10):  # 10 classes for MNIST\n",
    "            class_mask = (targets == c)\n",
    "            if class_mask.sum() > 0:\n",
    "                class_protos = prototypes[class_mask]\n",
    "                centroid = class_protos.mean(0)\n",
    "                prototype_loss += ((class_protos - centroid)**2).mean()\n",
    "        return prototype_loss\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        test_loader = torch.utils.data.DataLoader(self.test_data, batch_size=32)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output, _, _ = self.model(data)\n",
    "                pred = output.argmax(dim=1)\n",
    "                correct += pred.eq(target).sum().item()\n",
    "                total += target.size(0)\n",
    "                \n",
    "        accuracy = 100. * correct / total\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedProtoServer:\n",
    "    def __init__(self, global_model, device, num_clients=6):\n",
    "        self.global_model = global_model.to(device)\n",
    "        self.device = device\n",
    "        self.num_clients = num_clients\n",
    "    \n",
    "    def aggregate_models(self, client_models):\n",
    "        \"\"\"\n",
    "        Aggregate client models using FedAvg algorithm\n",
    "        \"\"\"\n",
    "        global_state_dict = self.global_model.state_dict()\n",
    "        \n",
    "        # Aggregate parameters\n",
    "        for key in global_state_dict.keys():\n",
    "            global_state_dict[key] = torch.stack([\n",
    "                client_models[i].state_dict()[key].to(self.device) \n",
    "                for i in range(len(client_models))\n",
    "            ]).mean(0)\n",
    "        \n",
    "        self.global_model.load_state_dict(global_state_dict)\n",
    "    \n",
    "    def distribute_model(self):\n",
    "        \"\"\"\n",
    "        Create a copy of the global model for distribution\n",
    "        \"\"\"\n",
    "        return copy.deepcopy(self.global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Round 1\n",
      "Client 0, Epoch 1: Loss: 2.3058, Accuracy: 9.49%\n",
      "Client 0, Epoch 2: Loss: 2.3057, Accuracy: 9.42%\n",
      "Client 0, Epoch 3: Loss: 2.3051, Accuracy: 9.92%\n",
      "Client 0, Epoch 4: Loss: 2.3055, Accuracy: 9.47%\n",
      "Client 0, Epoch 5: Loss: 2.3054, Accuracy: 9.26%\n",
      "Client 1, Epoch 1: Loss: 2.3056, Accuracy: 9.09%\n",
      "Client 1, Epoch 2: Loss: 2.3048, Accuracy: 10.68%\n",
      "Client 1, Epoch 3: Loss: 2.3053, Accuracy: 9.62%\n",
      "Client 1, Epoch 4: Loss: 2.3050, Accuracy: 9.82%\n",
      "Client 1, Epoch 5: Loss: 2.3050, Accuracy: 9.94%\n",
      "Client 2, Epoch 1: Loss: 2.3058, Accuracy: 9.54%\n",
      "Client 2, Epoch 2: Loss: 2.3065, Accuracy: 9.08%\n",
      "Client 2, Epoch 3: Loss: 2.3062, Accuracy: 9.47%\n",
      "Client 2, Epoch 4: Loss: 2.3065, Accuracy: 9.51%\n",
      "Client 2, Epoch 5: Loss: 2.3068, Accuracy: 9.39%\n",
      "Client 3, Epoch 1: Loss: 2.3044, Accuracy: 9.72%\n",
      "Client 3, Epoch 2: Loss: 2.3054, Accuracy: 9.58%\n",
      "Client 3, Epoch 3: Loss: 2.3050, Accuracy: 9.06%\n",
      "Client 3, Epoch 4: Loss: 2.3048, Accuracy: 9.20%\n",
      "Client 3, Epoch 5: Loss: 2.3049, Accuracy: 9.99%\n",
      "Client 4, Epoch 1: Loss: 2.3053, Accuracy: 9.30%\n",
      "Client 4, Epoch 2: Loss: 2.3061, Accuracy: 9.34%\n",
      "Client 4, Epoch 3: Loss: 2.3053, Accuracy: 9.42%\n",
      "Client 4, Epoch 4: Loss: 2.3057, Accuracy: 9.61%\n",
      "Client 4, Epoch 5: Loss: 2.3054, Accuracy: 9.33%\n",
      "Client 5, Epoch 1: Loss: 2.3058, Accuracy: 9.44%\n",
      "Client 5, Epoch 2: Loss: 2.3054, Accuracy: 9.44%\n",
      "Client 5, Epoch 3: Loss: 2.3054, Accuracy: 9.35%\n",
      "Client 5, Epoch 4: Loss: 2.3052, Accuracy: 9.49%\n",
      "Client 5, Epoch 5: Loss: 2.3055, Accuracy: 9.32%\n",
      "Client 0 Accuracy: 8.23%\n",
      "Client 1 Accuracy: 8.23%\n",
      "Client 2 Accuracy: 8.23%\n",
      "Client 3 Accuracy: 8.23%\n",
      "Client 4 Accuracy: 8.23%\n",
      "Client 5 Accuracy: 8.23%\n",
      "Round 1 Average Accuracy: 8.23%\n",
      "\n",
      "Round 2\n",
      "Client 0, Epoch 1: Loss: 2.3054, Accuracy: 9.81%\n",
      "Client 0, Epoch 2: Loss: 2.3057, Accuracy: 9.28%\n",
      "Client 0, Epoch 3: Loss: 2.3055, Accuracy: 9.56%\n",
      "Client 0, Epoch 4: Loss: 2.3056, Accuracy: 9.62%\n",
      "Client 0, Epoch 5: Loss: 2.3056, Accuracy: 9.45%\n",
      "Client 1, Epoch 1: Loss: 2.3053, Accuracy: 9.74%\n",
      "Client 1, Epoch 2: Loss: 2.3048, Accuracy: 9.35%\n",
      "Client 1, Epoch 3: Loss: 2.3057, Accuracy: 9.38%\n",
      "Client 1, Epoch 4: Loss: 2.3048, Accuracy: 9.12%\n",
      "Client 1, Epoch 5: Loss: 2.3053, Accuracy: 9.59%\n",
      "Client 2, Epoch 1: Loss: 2.3062, Accuracy: 8.63%\n",
      "Client 2, Epoch 2: Loss: 2.3065, Accuracy: 9.19%\n",
      "Client 2, Epoch 3: Loss: 2.3066, Accuracy: 9.33%\n",
      "Client 2, Epoch 4: Loss: 2.3059, Accuracy: 9.07%\n",
      "Client 2, Epoch 5: Loss: 2.3061, Accuracy: 9.42%\n",
      "Client 3, Epoch 1: Loss: 2.3054, Accuracy: 9.33%\n",
      "Client 3, Epoch 2: Loss: 2.3048, Accuracy: 9.70%\n",
      "Client 3, Epoch 3: Loss: 2.3050, Accuracy: 9.83%\n",
      "Client 3, Epoch 4: Loss: 2.3053, Accuracy: 9.20%\n",
      "Client 3, Epoch 5: Loss: 2.3052, Accuracy: 9.56%\n",
      "Client 4, Epoch 1: Loss: 2.3054, Accuracy: 9.23%\n",
      "Client 4, Epoch 2: Loss: 2.3056, Accuracy: 9.14%\n",
      "Client 4, Epoch 3: Loss: 2.3058, Accuracy: 9.08%\n",
      "Client 4, Epoch 4: Loss: 2.3060, Accuracy: 9.14%\n",
      "Client 4, Epoch 5: Loss: 2.3053, Accuracy: 9.63%\n",
      "Client 5, Epoch 1: Loss: 2.3048, Accuracy: 9.55%\n",
      "Client 5, Epoch 2: Loss: 2.3049, Accuracy: 9.70%\n",
      "Client 5, Epoch 3: Loss: 2.3054, Accuracy: 9.26%\n",
      "Client 5, Epoch 4: Loss: 2.3048, Accuracy: 9.54%\n",
      "Client 5, Epoch 5: Loss: 2.3050, Accuracy: 9.77%\n",
      "Client 0 Accuracy: 8.23%\n",
      "Client 1 Accuracy: 8.23%\n",
      "Client 2 Accuracy: 8.23%\n",
      "Client 3 Accuracy: 8.23%\n",
      "Client 4 Accuracy: 8.23%\n",
      "Client 5 Accuracy: 8.23%\n",
      "Round 2 Average Accuracy: 8.23%\n",
      "\n",
      "Round 3\n",
      "Client 0, Epoch 1: Loss: 2.3056, Accuracy: 9.70%\n",
      "Client 0, Epoch 2: Loss: 2.3058, Accuracy: 9.59%\n",
      "Client 0, Epoch 3: Loss: 2.3056, Accuracy: 9.52%\n",
      "Client 0, Epoch 4: Loss: 2.3057, Accuracy: 9.20%\n",
      "Client 0, Epoch 5: Loss: 2.3053, Accuracy: 9.68%\n",
      "Client 1, Epoch 1: Loss: 2.3048, Accuracy: 10.24%\n",
      "Client 1, Epoch 2: Loss: 2.3058, Accuracy: 9.34%\n",
      "Client 1, Epoch 3: Loss: 2.3053, Accuracy: 9.25%\n",
      "Client 1, Epoch 4: Loss: 2.3051, Accuracy: 9.55%\n",
      "Client 1, Epoch 5: Loss: 2.3052, Accuracy: 9.35%\n",
      "Client 2, Epoch 1: Loss: 2.3064, Accuracy: 9.30%\n",
      "Client 2, Epoch 2: Loss: 2.3063, Accuracy: 9.39%\n",
      "Client 2, Epoch 3: Loss: 2.3062, Accuracy: 9.18%\n",
      "Client 2, Epoch 4: Loss: 2.3063, Accuracy: 9.06%\n",
      "Client 2, Epoch 5: Loss: 2.3072, Accuracy: 9.22%\n",
      "Client 3, Epoch 1: Loss: 2.3050, Accuracy: 10.00%\n",
      "Client 3, Epoch 2: Loss: 2.3046, Accuracy: 9.97%\n",
      "Client 3, Epoch 3: Loss: 2.3048, Accuracy: 9.43%\n",
      "Client 3, Epoch 4: Loss: 2.3045, Accuracy: 10.26%\n",
      "Client 3, Epoch 5: Loss: 2.3050, Accuracy: 9.66%\n",
      "Client 4, Epoch 1: Loss: 2.3054, Accuracy: 9.03%\n",
      "Client 4, Epoch 2: Loss: 2.3055, Accuracy: 9.40%\n",
      "Client 4, Epoch 3: Loss: 2.3049, Accuracy: 9.80%\n",
      "Client 4, Epoch 4: Loss: 2.3062, Accuracy: 9.43%\n",
      "Client 4, Epoch 5: Loss: 2.3057, Accuracy: 9.12%\n",
      "Client 5, Epoch 1: Loss: 2.3050, Accuracy: 10.01%\n",
      "Client 5, Epoch 2: Loss: 2.3058, Accuracy: 9.18%\n",
      "Client 5, Epoch 3: Loss: 2.3052, Accuracy: 9.62%\n",
      "Client 5, Epoch 4: Loss: 2.3055, Accuracy: 9.67%\n",
      "Client 5, Epoch 5: Loss: 2.3054, Accuracy: 9.37%\n",
      "Client 0 Accuracy: 8.23%\n",
      "Client 1 Accuracy: 8.23%\n",
      "Client 2 Accuracy: 8.23%\n",
      "Client 3 Accuracy: 8.23%\n",
      "Client 4 Accuracy: 8.23%\n",
      "Client 5 Accuracy: 8.23%\n",
      "Round 3 Average Accuracy: 8.23%\n",
      "\n",
      "Round 4\n",
      "Client 0, Epoch 1: Loss: 2.3051, Accuracy: 9.14%\n",
      "Client 0, Epoch 2: Loss: 2.3060, Accuracy: 9.48%\n",
      "Client 0, Epoch 3: Loss: 2.3050, Accuracy: 9.57%\n",
      "Client 0, Epoch 4: Loss: 2.3059, Accuracy: 9.20%\n",
      "Client 0, Epoch 5: Loss: 2.3057, Accuracy: 9.02%\n",
      "Client 1, Epoch 1: Loss: 2.3064, Accuracy: 9.08%\n",
      "Client 1, Epoch 2: Loss: 2.3057, Accuracy: 9.24%\n",
      "Client 1, Epoch 3: Loss: 2.3049, Accuracy: 10.03%\n",
      "Client 1, Epoch 4: Loss: 2.3055, Accuracy: 9.33%\n",
      "Client 1, Epoch 5: Loss: 2.3054, Accuracy: 9.11%\n",
      "Client 2, Epoch 1: Loss: 2.3069, Accuracy: 9.09%\n",
      "Client 2, Epoch 2: Loss: 2.3063, Accuracy: 9.62%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Local training\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m clients:\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Aggregate models\u001b[39;00m\n\u001b[1;32m     36\u001b[0m client_models \u001b[38;5;241m=\u001b[39m [client\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m clients]\n",
      "Cell \u001b[0;32mIn[23], line 31\u001b[0m, in \u001b[0;36mFedProtoClient.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m proto_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_prototype_loss(prototypes, target)\n\u001b[1;32m     29\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m cls_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m proto_loss\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     34\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/Projects/FedProto/venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/FedProto/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/FedProto/venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize global model\n",
    "global_model = CNNModel().to(device)\n",
    "\n",
    "# Create server\n",
    "server = FedProtoServer(global_model, device)\n",
    "\n",
    "# Initialize clients\n",
    "clients = [\n",
    "    FedProtoClient(\n",
    "        copy.deepcopy(global_model),\n",
    "        client_datasets[i],\n",
    "        testset,\n",
    "        client_id=i,\n",
    "        device=device\n",
    "    ) for i in range(6)\n",
    "]\n",
    "\n",
    "# Training parameters\n",
    "num_rounds = 10\n",
    "local_epochs = 5\n",
    "global_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for round_idx in range(num_rounds):\n",
    "    print(f\"\\nRound {round_idx + 1}\")\n",
    "    \n",
    "    # Distribute global model to clients\n",
    "    for client in clients:\n",
    "        client.model = copy.deepcopy(server.global_model)\n",
    "        \n",
    "    # Local training\n",
    "    for client in clients:\n",
    "        client.train(local_epochs)\n",
    "        \n",
    "    # Aggregate models\n",
    "    client_models = [client.model for client in clients]\n",
    "    server.aggregate_models(client_models)\n",
    "    \n",
    "    # Evaluate global model\n",
    "    accuracies = []\n",
    "    for client in clients:\n",
    "        client.model = copy.deepcopy(server.global_model)\n",
    "        acc = client.evaluate()\n",
    "        accuracies.append(acc)\n",
    "        print(f\"Client {client.client_id} Accuracy: {acc:.2f}%\")\n",
    "    \n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    global_accuracies.append(avg_accuracy)\n",
    "    print(f\"Round {round_idx + 1} Average Accuracy: {avg_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy progression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(global_accuracies) + 1), global_accuracies, marker='o')\n",
    "plt.title('Global Model Accuracy over Communication Rounds')\n",
    "plt.xlabel('Communication Round')\n",
    "plt.ylabel('Average Accuracy (%)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save the final model\n",
    "torch.save(server.global_model.state_dict(), 'fedproto_mnist_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
